# -*- coding: utf-8 -*-
"""Fare_Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R8k27vXkOaQZ7r4nsg894oDq1UrIJ-0b
"""

import os
os.listdir("/content")

import pandas as pd

# Read cleaned dataset
df = pd.read_csv("/content/yellow_tripdata_2016-03_cleaned.csv")

# Quick check
df.head()
df.info()

df4 = df.copy()
print(df4.shape)
print(df4.columns)

"""**STEP 1— Convert Date & Time Columns into a Single Datetime Column**"""

df4['pickup_datetime'] = pd.to_datetime(df4['pickup_date'] + " " + df4['pickup_time'], errors='coerce')
df4['dropoff_datetime'] = pd.to_datetime(df4['dropoff_date'] + " " + df4['dropoff_time'], errors='coerce')

"""**STEP 2 — Extract Time Features (Feature Engineering)**"""

df4['pickup_hour'] = df4['pickup_datetime'].dt.hour
df4['pickup_day'] = df4['pickup_datetime'].dt.day
df4['pickup_month'] = df4['pickup_datetime'].dt.month
df4['pickup_year'] = df4['pickup_datetime'].dt.year
df4['pickup_dayofweek'] = df4['pickup_datetime'].dt.dayofweek

"""**STEP 3 — Remove Impossible Values (Negative or Zero Distance/Fare)**"""

df4 = df4[df4['fare_amount'] > 0]
df4 = df4[df4['trip_distance'] > 0]

"""**STEP 4 :Fix Outliers Using IQR Method**"""

import numpy as np

def remove_outliers_iqr(df, col):
    Q1 = df4[col].quantile(0.25)
    Q3 = df4[col].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR
    return df4[(df4[col] >= lower) & (df4[col] <= upper)]

df4 = remove_outliers_iqr(df4, 'trip_distance')
df4 = remove_outliers_iqr(df4, 'fare_amount')
df4 = remove_outliers_iqr(df4, 'total_amount')

"""**STEP 5 — Select Features for Fare Prediction**"""

feature_cols = [
    'trip_distance',
    'pickup_longitude', 'pickup_latitude',
    'dropoff_longitude', 'dropoff_latitude',
    'pickup_hour', 'pickup_day', 'pickup_month', 'pickup_dayofweek'
]

X = df4[feature_cols]
y = df4['total_amount']

"""**STEP 6: Split Train / Test Model**"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

"""**Step 7 : Scale Numerical Features**"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""Step 8 : Train Regression Model (RandomforestRegression)"""

from sklearn.ensemble import RandomForestRegressor

model = RandomForestRegressor(
    n_estimators=300,
    random_state=42,
    max_depth=None
)

model.fit(X_train_scaled, y_train)

"""Step 9 : Evaluate The Model"""

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

y_pred = model.predict(X_test_scaled)

print("MAE:", mean_absolute_error(y_test, y_pred))
print("RMSE:", np.sqrt(mean_squared_error(y_test, y_pred)))
print("R² Score:", r2_score(y_test, y_pred))

"""**Plot 1: Actual vs Predicted Fare**"""

import matplotlib.pyplot as plt

plt.figure(figsize=(8,6))
plt.scatter(y_test, y_pred, alpha=0.3)
plt.plot([y_test.min(), y_test.max()],
         [y_test.min(), y_test.max()],
         linestyle='--')

plt.xlabel("Actual Fare Amount")
plt.ylabel("Predicted Fare Amount")
plt.title("Actual vs Predicted Fare Amount")
plt.show()

"""**Plot 2: Residuals Plot (Errors)**"""

residuals = y_test - y_pred

plt.figure(figsize=(8,6))
plt.scatter(y_pred, residuals, alpha=0.3)
plt.axhline(0, linestyle='--')

plt.xlabel("Predicted Fare Amount")
plt.ylabel("Residuals (Actual - Predicted)")
plt.title("Residuals Plot")
plt.show()

"""**Plot 3: Distribution of Errors**"""

plt.figure(figsize=(8,6))
plt.hist(residuals, bins=50)
plt.xlabel("Residual Value")
plt.ylabel("Frequency")
plt.title("Distribution of Prediction Errors")
plt.show()

"""**Feature Importance**"""

import pandas as pd

feature_importance = pd.DataFrame({
    'Feature': X.columns,
    'Importance': model.feature_importances_
}).sort_values(by='Importance', ascending=False)

feature_importance.head(10)

import matplotlib.pyplot as plt

plt.figure(figsize=(8,6))
plt.barh(feature_importance['Feature'][:10],
         feature_importance['Importance'][:10])
plt.gca().invert_yaxis()
plt.title("Top 10 Feature Importances")
plt.xlabel("Importance Score")
plt.show()

"""Download The file of model"""

import joblib

# Save the trained model
joblib.dump(model, "fare_prediction_model.pkl")