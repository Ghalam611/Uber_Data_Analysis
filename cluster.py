# -*- coding: utf-8 -*-
"""cluster.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13qYH1QevPm9hFBXruFBAkijeZ4NqCJ8p
"""

import pandas as pd
import os
import kagglehub
import matplotlib.pyplot as plt
import seaborn as sns

# Download dataset from KaggleHub
path = kagglehub.dataset_download("elemento/nyc-yellow-taxi-trip-data")
print("Path to dataset files:", path)

csv_file = os.path.join(path, "yellow_tripdata_2016-03.csv")

# Load dataset into a DataFrame
df = pd.read_csv(csv_file)

# Display basic info about the dataset
print(df.info())
# Display the shape of the DataFrame
print(df.shape)
# Display statistical summary for numeric columns
print(df.describe())

# Convert pickup and dropoff time columns from string to datetime format
df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])
df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])

# Split datetime into date and time
df['pickup_date'] = df['tpep_pickup_datetime'].dt.date
df['pickup_time'] = df['tpep_pickup_datetime'].dt.time
df['dropoff_date'] = df['tpep_dropoff_datetime'].dt.date
df['dropoff_time'] = df['tpep_dropoff_datetime'].dt.time


# Remove trips with zero or extremely large distances (>90 miles)
df = df[(df['trip_distance'] > 0) & (df['trip_distance'] <= 90)]
# Remove trips with zero or extremely high fares (>850 dollars)
df = df[(df['fare_amount'] > 0) & (df['fare_amount'] < 850)]



# Drop unnecessary columns
cols_to_delete = [
    'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count',
    'RatecodeID', 'store_and_fwd_flag', 'payment_type', 'extra','VendorID',
    'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge'
]

df = df.drop(columns=cols_to_delete)

# Print number of missing values per column
print("Missing values:\n", df.isnull().sum()) #There are no null values in the data
# Print number of duplicated rows
print("Number of duplicated rows:", df.duplicated().sum()) #There are no duplicated rows

"""#PRINT SHAPE and data cleaning"""

df.shape

# Define valid latitude and longitude boundaries for NYC
NYC_LAT_MIN = 40.4774
NYC_LAT_MAX = 40.9176
NYC_LON_MIN = -74.2591
NYC_LON_MAX = -73.7004

# Filter trips where both pickup and dropoff locations are within NYC bounds
df2 = df[
    (df['pickup_latitude'] >= NYC_LAT_MIN) &
    (df['pickup_latitude'] <= NYC_LAT_MAX) &
    (df['pickup_longitude'] >= NYC_LON_MIN) &
    (df['pickup_longitude'] <= NYC_LON_MAX) &
    (df['dropoff_latitude'] >= NYC_LAT_MIN) &
    (df['dropoff_latitude'] <= NYC_LAT_MAX) &
    (df['dropoff_longitude'] >= NYC_LON_MIN) &
    (df['dropoff_longitude'] <= NYC_LON_MAX)
]
df2.shape

import folium
from folium.plugins import HeatMap

# Initialize the map centered on NYC with a suitable zoom level
m = folium.Map(location=[40.75, -73.97], zoom_start=11)

heat_data = df2[['pickup_latitude', 'pickup_longitude']].values.tolist()

# Add heatmap layer to visualize pickup density
HeatMap(heat_data, radius=8).add_to(m)

# Save the interactive heatmap to an HTML file
m.save("heatmap1.html")

"""# KMeans"""

from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# Range of cluster numbers to test (from 2 to 14)
inertias = []
K_range = range(2, 15)
coords = df2[['pickup_latitude', 'pickup_longitude']]

# Train KMeans for each K value
for k in K_range:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(coords)
    inertias.append(kmeans.inertia_)

# Plot the Elbow Method curve
plt.figure(figsize=(8,5))
plt.plot(K_range, inertias, marker='o')
plt.xlabel('Number of Clusters (K)')
plt.ylabel('Inertia')
plt.title('Elbow Method')
plt.grid(True)
plt.show()

coords = df2[['pickup_latitude', 'pickup_longitude']]
# Train K-Means with 5 number of clusters
kmeans = KMeans(n_clusters=5, random_state=42)
df2['clusterkm'] = kmeans.fit_predict(coords)

print(df2['clusterkm'].value_counts())

import joblib
# Save the trained K-Means model to disk
joblib.dump(kmeans, "kmeans_pickups.pkl")

import plotly.express as px
# Compute map center using mean coordinates
center_lat = df2['pickup_latitude'].mean()
center_lon = df2['pickup_longitude'].mean()
# Visualize clusters on an interactive map
fig = px.scatter_mapbox(
    df2.sample(n=100_000, random_state=42),
    lat="pickup_latitude",
    lon="pickup_longitude",
    color="clusterkm",
    zoom=9,
    height=900,
    center={"lat": center_lat, "lon": center_lon}
)
# Use OpenStreetMap as the basemap
fig.update_layout(mapbox_style="open-street-map")
fig.show()

"""# DBSCAN"""

from sklearn.cluster import DBSCAN
from sklearn.neighbors import BallTree
import numpy as np

# Randomly sample 100,000 records to reduce computation cost
df_small = df2.sample(n=100_000, random_state=42)

# Convert latitude and longitude from degrees to radians (required for haversine)
coords = np.radians(df_small[['pickup_latitude','pickup_longitude']].values)

# Initialize DBSCAN with distance in kilometers converted to radians
# eps defines the neighborhood radius
# min_samples defines the minimum points to form a dense region
# BallTree is used for faster spatial queries
db = DBSCAN(
    eps=0.5 / 6371,
    min_samples=50,
    algorithm='ball_tree',
    metric='haversine'
)

df_small['clusterdb'] = db.fit_predict(coords)

# Save the trained DBSCAN model to disk using joblib
joblib.dump(db, "dbscan_pickups.pkl")

# Display the number of points in each cluster
df_small['clusterdb'].value_counts()

# Create a figure for visualizing DBSCAN clustering results
plt.figure(figsize=(8, 6))

plt.scatter(
    df_small['pickup_longitude'],
    df_small['pickup_latitude'],
    c=df_small['clusterdb'],
    cmap='tab20',
    s=5
)

plt.xlabel("Longitude")
plt.ylabel("Latitude")
plt.title("DBSCAN Clustering (NYC Pickups)")
plt.colorbar(label="Cluster ID")

plt.show()

# Create an interactive Mapbox scatter plot for pickup locations
fig = px.scatter_mapbox(
    df_small,
    lat="pickup_latitude",
    lon="pickup_longitude",
    color="clusterdb",
    zoom=9,
    height=600,
    center={"lat": center_lat, "lon": center_lon}
)
# Use OpenStreetMap as the basemap
fig.update_layout(mapbox_style="open-street-map")
fig.show()